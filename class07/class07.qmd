---
title: "Class 7: Machine Learning 1"
author: "Kira"
format: pdf
---

In this class we will explore clustering and dimensionality reduction methods.

## K-means

Make up some input data where we know what the answer should be.

```{r}
tmp <- c(rnorm(30, -3),rnorm(30,+3))
x <- cbind(x=tmp,y=rev(tmp))
head(x)
```
Quick plot of x to see the two groups at -3,+3 and +3,-3.
```{r}
plot(x)
```

Use the `kmeans()` function, setting k to 2 and nstart=20.

```{r}
km <- kmeans(x,centers=2,nstart=20)
km
```

>Q. How many points are in each cluster?

```{r}
km$size
```

>Q. What 'component' of your result object details cluster assignment/membership and cluster center?

```{r}
km$cluster
km$centers
```

>Q. Plot x colored by the kmeans cluster assignment and add cluster centers as blue points.

```{r}
plot(x, col=km$cluster)
points(km$centers,col="blue", pch=15)
```

Play with kmeans and ask for different number of clusters.
```{r}
km <- kmeans(x,centers=4,nstart=20)
plot(x, col=km$cluster)
points(km$centers,col="blue", pch=16)
```

# Hierarchical Clustering

This is another very useful and widely employed clustering method which has the advantage over k-means in that is can help reveal something about the true grouping in your data set.

The `hclust()` function wants a distance matrix as input. We can get this from the `dist()` function.

```{r}
d <- dist(x)
hc <- hclust(d)
hc
```

There is a plot method for `hclust()` results:

```{r}
plot(hc)
abline(h=10,col="red")
```

To get my cluster membership vector I need to "cut" my tree to yield sub-trees or branches with all the members of a given cluster. The function to do this is called `cutree()`.

```{r}
grps <- cutree(hc,h=10)
grps
```

```{r}
plot(x,col=grps)
```
```{r}
plot(hc)
```

It is often helpful to use the `k=` argument to `cutree()` rather than the `h=` height of cutting with `cutree()`. This will cut the tree to yield the number of clusters you want.

```{r}
cutree(hc,k=4)
```

# Principal Component Analysis (PCA)

The base R function for PCA is called `prcomp()`.
Let's play with some 17D data (a very small dataset) and see how PCA can help.

# PCA of UK Food Data

Import the data

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url, row.names=1)
head(x)
```
>Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
dim(x)
```

I used the `dim()` function to find the number of columns and rows.

```{r}
# Note how the minus indexing works
#rownames(x) <- x[,1]
#x <- x[,-1]
#head(x)
```

There are 17 rows and 4 columns once I adjusted it so that row-names was not the first column. 

>Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

The second approach (fixing the problem when importing the data) is probably ideal since running the `x <- x[-1]` multiple times will remove a column each time. I have commented out these lines for subsequent runs of code.

```{r}
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```

>Q3: Changing what optional argument in the above barplot() function results in the following plot?

Changing the "beside" argument to be "FALSE" or "F" changes the `barplot()`. Leaving this argument out would have the same effect since the default value for this argument is "FALSE".

```{r}
pairs(x, col=rainbow(10), pch=16)
```

>Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

In this case, the pair-wise plots show comparisons between all countries vs. all other countries in different food categories (i.e there is a plot where each country is on the x-axis and another plot where it is on the y-axis vs. all other countries). If a point lies on the diagonal of a given plot, the two countries have the same value for that food category. 

>Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

N. Ireland's data is least similar to other countries in the dataset (i.e values for respective food categories are not very often the same between N. Ireland vs. England, Wales, or Scotland).

```{r}
# Use the prcomp() PCA function 
pca <- prcomp( t(x) )
summary(pca)
```

A "PCA plot": PC1 vs. PC2

```{r}
pca$x
```


>Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

```{r}
# Plot PC1 vs PC2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))
```

>Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.

```{r}
# Plot PC1 vs PC2 with country names colored
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x), col=c("orange", "red", "blue", "darkgreen"))
```

```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
```

```{r}
z <- summary(pca)
z$importance
```

```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```

```{r}
## Lets focus on PC1 as it accounts for > 90% of variance 
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )
```
